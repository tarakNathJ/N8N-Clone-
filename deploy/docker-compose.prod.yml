services:
  # =============================primary backend==========================
  primary_backend:
    image: taraknathjana09/n8n_primary_backend
    container_name: primary_backend
    ports:
      - "4040:4040"
    restart: always
    networks:
      - backend_network
    depends_on:
      - postgresql
    environment:
      PORT: 4040
      DATABASE_URL: "postgresql://postgres:mysecretpassword@postgresql:5432/postgres"
      JWT_SECRET: "mysecret"
      NODE_OPTIONS: "--max-old-space-size=256"
    deploy:
      resources:
        limits:
          memory: 300M

  # ============================= workflow ====================================
  workflow:
    image: taraknathjana09/n8n_workflow:v1
    container_name: workflow
    ports:
      - "4080:4080"
    networks:
      - backend_network
    depends_on:
      - postgresql
    restart: always
    environment:
      ACCESS_TOKEN_SECRET: "mysecret"
      DATABASE_URL: "postgresql://postgres:mysecretpassword@postgresql:5432/postgres"
      PORT: 4080
      WORKFLOW_SERVER_URL: http://workflow:4080/api/workflow/webhook
      NODE_OPTIONS: "--max-old-space-size=256"
    deploy:
      resources:
        limits:
          memory: 300M

  # ============================= cron worker ====================================
  cron_worker:
    image: taraknathjana09/n8n_cron_worker:v4
    container_name: cron_worker
    networks:
      - backend_network
    depends_on:
      - kafka
      - postgresql
    restart: always
    environment:
      KAFKA_TOPIC: USER-TRADE
      KAFKA_CLIENT_ID: mykafka
      KAFKA_BROKER: "kafka:9092"
      DATABASE_URL: "postgresql://postgres:mysecretpassword@postgresql:5432/postgres"
      NODE_OPTIONS: "--max-old-space-size=128"
    deploy:
      resources:
        limits:
          memory: 150M

  processar:
    image: taraknathjana09/n8n_processar:v1
    container_name: processar
    networks:
      - backend_network
    depends_on:
      - kafka
      - postgresql
    restart: always
    environment:
      KAFKA_TOPIC: USER-TRADE
      KAFKA_CLIENT_ID: mykafka
      KAFKA_BROKERS: "kafka:9092"
      DATABASE_URL: "postgresql://postgres:mysecretpassword@postgresql:5432/postgres"
      NODE_OPTIONS: "--max-old-space-size=128"
    deploy:
      resources:
        limits:
          memory: 150M

  worker:
    image: taraknathjana09/n8n_worker:v1
    container_name: worker
    networks:
      - backend_network
    depends_on:
      - kafka
      - postgresql
    restart: always
    environment:
      KAFKA_TOPIC: USER-TRADE
      KAFKA_GROUP_ID: worker-group
      KAFKA_CLIENT_ID: mykafka
      KAFKA_BROCKER: "kafka:9092"
      DATABASE_URL: "postgresql://postgres:mysecretpassword@postgresql:5432/postgres"
      NODE_OPTIONS: "--max-old-space-size=128"
    deploy:
      resources:
        limits:
          memory: 150M

  # ============================= postgresql ====================================

  postgresql:
    image: postgres:bookworm
    container_name: postgresql_db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: mysecretpassword
      POSTGRES_DB: postgres
      POSTGRES_MAX_CONNECTIONS: 50
      POSTGRES_SHARED_BUFFERS: 64MB
    ports:
      - "5432:5432"
    volumes:
      - postgresql_db:/var/lib/postgresql/data
    restart: always
    networks:
      - backend_network
    deploy:
      resources:
        limits:
          memory: 256M
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================= kafka ====================================
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms128M"
      KAFKA_NUM_NETWORK_THREADS: 2
      KAFKA_NUM_IO_THREADS: 2
      KAFKA_NUM_REPLICA_FETCHERS: 1
      KAFKA_QUEUED_MAX_REQUESTS: 20
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 10000
      KAFKA_LOG_FLUSH_INTERVAL_MS: 3000
      KAFKA_LOG_SEGMENT_BYTES: 468435456
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_RETENTION_HOURS: 6
      KAFKA_LOG_CLEANER_ENABLE: "true"
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - kafka-data:/var/lib/kafka/data
    restart: unless-stopped
    networks:
      - backend_network
    deploy:
      resources:
        limits:
          memory: 512M
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-broker-api-versions.sh --bootstrap-server localhost:9092",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

networks:
  backend_network:
    driver: bridge

volumes:
  kafka-data:
  postgresql_db:
